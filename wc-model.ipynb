{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40924e60",
   "metadata": {},
   "source": [
    "# World Cup Prediction Model\n",
    "## Industry-Standard ML Framework for World Cup Predictions\n",
    "\n",
    "This notebook implements a comprehensive machine learning pipeline for predicting World Cup outcomes using historical football data from 1872 to present.\n",
    "\n",
    "### Features:\n",
    "- **Advanced Feature Engineering**: Team strength, form, head-to-head records, tournament-specific features\n",
    "- **Multiple ML Models**: XGBoost, LightGBM, CatBoost with ensemble methods\n",
    "- **Hyperparameter Optimization**: Using Optuna for automated tuning\n",
    "- **Tournament Simulation**: Complete World Cup simulation engine\n",
    "- **API Integration**: FastAPI endpoints for dashboard integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31aff7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n",
      "üìä Pandas version: 2.3.1\n",
      "ü§ñ XGBoost version: 3.0.2\n",
      "‚ö° LightGBM version: 4.6.0\n",
      "üöÄ CatBoost version: 1.2.8\n"
     ]
    }
   ],
   "source": [
    "# Core Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Try importing advanced ML libraries with fallbacks\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGB_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è  XGBoost not available, using sklearn GradientBoostingClassifier instead\")\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    LGB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LGB_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è  LightGBM not available\")\n",
    "\n",
    "try:\n",
    "    import catboost as cb\n",
    "    CB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    CB_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è  CatBoost not available\")\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "import optuna\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Utilities\n",
    "from datetime import datetime, timedelta\n",
    "import joblib\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "\n",
    "# API Framework\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import uvicorn\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"üìä Pandas version: {pd.__version__}\")\n",
    "if XGB_AVAILABLE:\n",
    "    print(f\"ü§ñ XGBoost version: {xgb.__version__}\")\n",
    "if LGB_AVAILABLE:\n",
    "    print(f\"‚ö° LightGBM version: {lgb.__version__}\")\n",
    "if CB_AVAILABLE:\n",
    "    print(f\"üöÄ CatBoost version: {cb.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7c9df2",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Exploration\n",
    "Loading all historical football data and understanding its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c91d8b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading datasets...\n",
      "üìä Results data: 48,366 matches\n",
      "‚öΩ Goalscorers data: 44,447 goals\n",
      "ü•Ö Shootouts data: 650 penalty shootouts\n",
      "üè≥Ô∏è Former names: 34 team name changes\n",
      "\n",
      "==================================================\n",
      "üìà DATASET OVERVIEW\n",
      "==================================================\n",
      "\n",
      "Results Dataset:\n",
      "  Shape: (48366, 9)\n",
      "  Columns: ['date', 'home_team', 'away_team', 'home_score', 'away_score', 'tournament', 'city', 'country', 'neutral']\n",
      "  Date range: 1872-11-30 to 2025-07-06\n",
      "\n",
      "Goalscorers Dataset:\n",
      "  Shape: (44447, 8)\n",
      "  Columns: ['date', 'home_team', 'away_team', 'team', 'scorer', 'minute', 'own_goal', 'penalty']\n",
      "  Date range: 1916-07-02 to 2025-07-06\n",
      "\n",
      "Shootouts Dataset:\n",
      "  Shape: (650, 5)\n",
      "  Columns: ['date', 'home_team', 'away_team', 'winner', 'first_shooter']\n",
      "  Date range: 1967-08-22 to 2025-06-29\n",
      "\n",
      "Former Names Dataset:\n",
      "  Shape: (34, 4)\n",
      "  Columns: ['current', 'former', 'start_date', 'end_date']\n",
      "  Date range: N/A to N/A\n",
      "\n",
      "üåç Unique teams in results: 332\n",
      "üèÜ Unique tournaments: 184\n",
      "üìÖ Data spans 152.6 years\n"
     ]
    }
   ],
   "source": [
    "# Load all datasets\n",
    "print(\"üîÑ Loading datasets...\")\n",
    "\n",
    "# Load main results data\n",
    "results_df = pd.read_csv('results.csv')\n",
    "print(f\"üìä Results data: {results_df.shape[0]:,} matches\")\n",
    "\n",
    "# Load goalscorers data\n",
    "goalscorers_df = pd.read_csv('goalscorers.csv')\n",
    "print(f\"‚öΩ Goalscorers data: {goalscorers_df.shape[0]:,} goals\")\n",
    "\n",
    "# Load shootouts data\n",
    "shootouts_df = pd.read_csv('shootouts.csv')\n",
    "print(f\"ü•Ö Shootouts data: {shootouts_df.shape[0]:,} penalty shootouts\")\n",
    "\n",
    "# Load former names mapping\n",
    "former_names_df = pd.read_csv('former_names.csv')\n",
    "print(f\"üè≥Ô∏è Former names: {former_names_df.shape[0]:,} team name changes\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üìà DATASET OVERVIEW\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Display basic info about each dataset\n",
    "datasets = {\n",
    "    'Results': results_df,\n",
    "    'Goalscorers': goalscorers_df, \n",
    "    'Shootouts': shootouts_df,\n",
    "    'Former Names': former_names_df\n",
    "}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    print(f\"\\n{name} Dataset:\")\n",
    "    print(f\"  Shape: {df.shape}\")\n",
    "    print(f\"  Columns: {list(df.columns)}\")\n",
    "    print(f\"  Date range: {df['date'].min() if 'date' in df.columns else 'N/A'} to {df['date'].max() if 'date' in df.columns else 'N/A'}\")\n",
    "    \n",
    "print(f\"\\nüåç Unique teams in results: {len(set(results_df['home_team'].unique()) | set(results_df['away_team'].unique()))}\")\n",
    "print(f\"üèÜ Unique tournaments: {results_df['tournament'].nunique()}\")\n",
    "print(f\"üìÖ Data spans {(pd.to_datetime(results_df['date'].max()) - pd.to_datetime(results_df['date'].min())).days / 365.25:.1f} years\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3864803e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Preprocessing data...\n",
      "üìà Modern results (1990+): 31,253 matches\n",
      "üåç Modern teams: 322\n",
      "\n",
      "üìã Sample of modern results:\n",
      "            date home_team  away_team  home_score  away_score tournament  \\\n",
      "17113 1990-01-12   Algeria       Mali           5           0   Friendly   \n",
      "17114 1990-01-14   Algeria   Cameroon           3           1   Friendly   \n",
      "17115 1990-01-17    Greece    Belgium           2           0   Friendly   \n",
      "17116 1990-01-17    Mexico  Argentina           2           0   Friendly   \n",
      "17117 1990-01-20    Malawi   Tanzania           2           2   Friendly   \n",
      "\n",
      "              city        country  neutral  \n",
      "17113        Paris         France     True  \n",
      "17114        Paris         France     True  \n",
      "17115       Athens         Greece    False  \n",
      "17116  Los Angeles  United States     True  \n",
      "17117      Lobamba      Swaziland     True  \n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing and Team Name Standardization\n",
    "print(\"üîß Preprocessing data...\")\n",
    "\n",
    "# Convert dates to datetime\n",
    "results_df['date'] = pd.to_datetime(results_df['date'])\n",
    "goalscorers_df['date'] = pd.to_datetime(goalscorers_df['date'])\n",
    "shootouts_df['date'] = pd.to_datetime(shootouts_df['date'])\n",
    "\n",
    "# Create team name mapping from former names\n",
    "def create_team_mapping(former_names_df):\n",
    "    \"\"\"Create a mapping from former team names to current names\"\"\"\n",
    "    team_mapping = {}\n",
    "    \n",
    "    for _, row in former_names_df.iterrows():\n",
    "        team_mapping[row['former']] = row['current']\n",
    "    \n",
    "    return team_mapping\n",
    "\n",
    "team_mapping = create_team_mapping(former_names_df)\n",
    "\n",
    "def standardize_team_name(name, mapping):\n",
    "    \"\"\"Standardize team names using the mapping\"\"\"\n",
    "    return mapping.get(name, name)\n",
    "\n",
    "# Apply team name standardization\n",
    "results_df['home_team'] = results_df['home_team'].apply(lambda x: standardize_team_name(x, team_mapping))\n",
    "results_df['away_team'] = results_df['away_team'].apply(lambda x: standardize_team_name(x, team_mapping))\n",
    "\n",
    "# Focus on modern football (post-1990) for primary analysis but keep historical data for context\n",
    "modern_results = results_df[results_df['date'] >= '1990-01-01'].copy()\n",
    "\n",
    "print(f\"üìà Modern results (1990+): {modern_results.shape[0]:,} matches\")\n",
    "print(f\"üåç Modern teams: {len(set(modern_results['home_team'].unique()) | set(modern_results['away_team'].unique()))}\")\n",
    "\n",
    "# Display sample of data\n",
    "print(\"\\nüìã Sample of modern results:\")\n",
    "print(modern_results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05972f1e",
   "metadata": {},
   "source": [
    "## 2. Advanced Feature Engineering\n",
    "Creating sophisticated features to capture team strength, form, and match dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3f2c35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Football Feature Engine initialized!\n"
     ]
    }
   ],
   "source": [
    "class FootballFeatureEngine:\n",
    "    \"\"\"\n",
    "    Advanced feature engineering for football match prediction.\n",
    "    \n",
    "    Features include:\n",
    "    - ELO rating system\n",
    "    - Recent form analysis\n",
    "    - Head-to-head records\n",
    "    - Goal scoring patterns\n",
    "    - Tournament-specific performance\n",
    "    - Home advantage analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, k_factor=20, form_window=10):\n",
    "        self.k_factor = k_factor\n",
    "        self.form_window = form_window\n",
    "        self.elo_ratings = {}\n",
    "        self.team_stats = defaultdict(lambda: defaultdict(list))\n",
    "        \n",
    "    def expected_score(self, rating_a, rating_b):\n",
    "        \"\"\"Calculate expected score using ELO formula\"\"\"\n",
    "        return 1 / (1 + 10**((rating_b - rating_a) / 400))\n",
    "    \n",
    "    def update_elo(self, team_a, team_b, score_a, score_b, is_neutral=False):\n",
    "        \"\"\"Update ELO ratings after a match\"\"\"\n",
    "        # Initialize ratings if not present\n",
    "        if team_a not in self.elo_ratings:\n",
    "            self.elo_ratings[team_a] = 1500\n",
    "        if team_b not in self.elo_ratings:\n",
    "            self.elo_ratings[team_b] = 1500\n",
    "            \n",
    "        # Calculate current ratings\n",
    "        rating_a = self.elo_ratings[team_a]\n",
    "        rating_b = self.elo_ratings[team_b]\n",
    "        \n",
    "        # Adjust for home advantage (unless neutral venue)\n",
    "        home_advantage = 100 if not is_neutral else 0\n",
    "        expected_a = self.expected_score(rating_a + home_advantage, rating_b)\n",
    "        expected_b = self.expected_score(rating_b, rating_a + home_advantage)\n",
    "        \n",
    "        # Determine actual result\n",
    "        if score_a > score_b:\n",
    "            actual_a, actual_b = 1, 0\n",
    "        elif score_a < score_b:\n",
    "            actual_a, actual_b = 0, 1\n",
    "        else:\n",
    "            actual_a, actual_b = 0.5, 0.5\n",
    "            \n",
    "        # Goal difference multiplier (bigger wins = larger rating changes)\n",
    "        goal_diff_multiplier = max(1, abs(score_a - score_b) / 2)\n",
    "        \n",
    "        # Update ratings\n",
    "        self.elo_ratings[team_a] += self.k_factor * goal_diff_multiplier * (actual_a - expected_a)\n",
    "        self.elo_ratings[team_b] += self.k_factor * goal_diff_multiplier * (actual_b - expected_b)\n",
    "        \n",
    "        return self.elo_ratings[team_a], self.elo_ratings[team_b]\n",
    "    \n",
    "    def calculate_team_form(self, team, date, matches_df, window=10):\n",
    "        \"\"\"Calculate recent form for a team\"\"\"\n",
    "        # Get recent matches for the team\n",
    "        team_matches = matches_df[\n",
    "            ((matches_df['home_team'] == team) | (matches_df['away_team'] == team)) &\n",
    "            (matches_df['date'] < date)\n",
    "        ].sort_values('date', ascending=False).head(window)\n",
    "        \n",
    "        if len(team_matches) == 0:\n",
    "            return {'form_points': 0, 'goals_for': 0, 'goals_against': 0, 'matches_played': 0}\n",
    "        \n",
    "        points = 0\n",
    "        goals_for = 0\n",
    "        goals_against = 0\n",
    "        \n",
    "        for _, match in team_matches.iterrows():\n",
    "            if match['home_team'] == team:\n",
    "                goals_for += match['home_score']\n",
    "                goals_against += match['away_score']\n",
    "                if match['home_score'] > match['away_score']:\n",
    "                    points += 3\n",
    "                elif match['home_score'] == match['away_score']:\n",
    "                    points += 1\n",
    "            else:\n",
    "                goals_for += match['away_score']\n",
    "                goals_against += match['home_score']\n",
    "                if match['away_score'] > match['home_score']:\n",
    "                    points += 3\n",
    "                elif match['away_score'] == match['home_score']:\n",
    "                    points += 1\n",
    "        \n",
    "        return {\n",
    "            'form_points': points / len(team_matches) if len(team_matches) > 0 else 0,\n",
    "            'goals_for': goals_for / len(team_matches) if len(team_matches) > 0 else 0,\n",
    "            'goals_against': goals_against / len(team_matches) if len(team_matches) > 0 else 0,\n",
    "            'matches_played': len(team_matches)\n",
    "        }\n",
    "    \n",
    "    def head_to_head_record(self, team_a, team_b, date, matches_df, years_back=10):\n",
    "        \"\"\"Calculate head-to-head record between two teams\"\"\"\n",
    "        cutoff_date = date - timedelta(days=365 * years_back)\n",
    "        \n",
    "        h2h_matches = matches_df[\n",
    "            (((matches_df['home_team'] == team_a) & (matches_df['away_team'] == team_b)) |\n",
    "             ((matches_df['home_team'] == team_b) & (matches_df['away_team'] == team_a))) &\n",
    "            (matches_df['date'] >= cutoff_date) &\n",
    "            (matches_df['date'] < date)\n",
    "        ]\n",
    "        \n",
    "        if len(h2h_matches) == 0:\n",
    "            return {'h2h_wins': 0, 'h2h_draws': 0, 'h2h_losses': 0, 'h2h_matches': 0}\n",
    "        \n",
    "        wins, draws, losses = 0, 0, 0\n",
    "        \n",
    "        for _, match in h2h_matches.iterrows():\n",
    "            if match['home_team'] == team_a:\n",
    "                if match['home_score'] > match['away_score']:\n",
    "                    wins += 1\n",
    "                elif match['home_score'] == match['away_score']:\n",
    "                    draws += 1\n",
    "                else:\n",
    "                    losses += 1\n",
    "            else:\n",
    "                if match['away_score'] > match['home_score']:\n",
    "                    wins += 1\n",
    "                elif match['away_score'] == match['home_score']:\n",
    "                    draws += 1\n",
    "                else:\n",
    "                    losses += 1\n",
    "        \n",
    "        return {\n",
    "            'h2h_wins': wins,\n",
    "            'h2h_draws': draws,\n",
    "            'h2h_losses': losses,\n",
    "            'h2h_matches': len(h2h_matches)\n",
    "        }\n",
    "    \n",
    "    def tournament_experience(self, team, tournament, date, matches_df):\n",
    "        \"\"\"Calculate team's experience in specific tournament\"\"\"\n",
    "        tournament_matches = matches_df[\n",
    "            ((matches_df['home_team'] == team) | (matches_df['away_team'] == team)) &\n",
    "            (matches_df['tournament'] == tournament) &\n",
    "            (matches_df['date'] < date)\n",
    "        ]\n",
    "        \n",
    "        return len(tournament_matches)\n",
    "    \n",
    "    def build_features(self, matches_df, include_elo=True):\n",
    "        \"\"\"Build comprehensive feature set for all matches\"\"\"\n",
    "        print(\"üèóÔ∏è Building advanced features...\")\n",
    "        \n",
    "        # Sort matches by date\n",
    "        matches_df = matches_df.sort_values('date').reset_index(drop=True)\n",
    "        \n",
    "        features = []\n",
    "        \n",
    "        # Initialize ELO ratings if needed\n",
    "        if include_elo:\n",
    "            self.elo_ratings = {}\n",
    "        \n",
    "        for idx, match in matches_df.iterrows():\n",
    "            if idx % 5000 == 0:\n",
    "                print(f\"   Processing match {idx:,}/{len(matches_df):,}\")\n",
    "                \n",
    "            home_team = match['home_team']\n",
    "            away_team = match['away_team']\n",
    "            match_date = match['date']\n",
    "            \n",
    "            # Get current ELO ratings before match\n",
    "            if include_elo:\n",
    "                home_elo = self.elo_ratings.get(home_team, 1500)\n",
    "                away_elo = self.elo_ratings.get(away_team, 1500)\n",
    "                elo_diff = home_elo - away_elo\n",
    "            else:\n",
    "                home_elo = away_elo = elo_diff = 0\n",
    "            \n",
    "            # Calculate form\n",
    "            home_form = self.calculate_team_form(home_team, match_date, matches_df, self.form_window)\n",
    "            away_form = self.calculate_team_form(away_team, match_date, matches_df, self.form_window)\n",
    "            \n",
    "            # Head-to-head record\n",
    "            h2h = self.head_to_head_record(home_team, away_team, match_date, matches_df)\n",
    "            \n",
    "            # Tournament experience\n",
    "            home_tournament_exp = self.tournament_experience(home_team, match['tournament'], match_date, matches_df)\n",
    "            away_tournament_exp = self.tournament_experience(away_team, match['tournament'], match_date, matches_df)\n",
    "            \n",
    "            # Build feature vector\n",
    "            feature_vector = {\n",
    "                # Basic info\n",
    "                'home_team': home_team,\n",
    "                'away_team': away_team,\n",
    "                'date': match_date,\n",
    "                'tournament': match['tournament'],\n",
    "                'neutral': 1 if match['neutral'] else 0,\n",
    "                \n",
    "                # ELO features\n",
    "                'home_elo': home_elo,\n",
    "                'away_elo': away_elo,\n",
    "                'elo_diff': elo_diff,\n",
    "                \n",
    "                # Form features\n",
    "                'home_form_points': home_form['form_points'],\n",
    "                'away_form_points': away_form['form_points'],\n",
    "                'home_goals_for_avg': home_form['goals_for'],\n",
    "                'away_goals_for_avg': away_form['goals_for'],\n",
    "                'home_goals_against_avg': home_form['goals_against'],\n",
    "                'away_goals_against_avg': away_form['goals_against'],\n",
    "                'form_diff': home_form['form_points'] - away_form['form_points'],\n",
    "                \n",
    "                # Head-to-head features\n",
    "                'h2h_home_wins': h2h['h2h_wins'],\n",
    "                'h2h_draws': h2h['h2h_draws'],\n",
    "                'h2h_away_wins': h2h['h2h_losses'],\n",
    "                'h2h_total_matches': h2h['h2h_matches'],\n",
    "                \n",
    "                # Tournament experience\n",
    "                'home_tournament_exp': home_tournament_exp,\n",
    "                'away_tournament_exp': away_tournament_exp,\n",
    "                'tournament_exp_diff': home_tournament_exp - away_tournament_exp,\n",
    "                \n",
    "                # Target variables\n",
    "                'home_score': match['home_score'],\n",
    "                'away_score': match['away_score'],\n",
    "                'result': 1 if match['home_score'] > match['away_score'] else (0 if match['home_score'] == match['away_score'] else -1)\n",
    "            }\n",
    "            \n",
    "            features.append(feature_vector)\n",
    "            \n",
    "            # Update ELO ratings after processing this match\n",
    "            if include_elo:\n",
    "                self.update_elo(home_team, away_team, match['home_score'], match['away_score'], match['neutral'])\n",
    "        \n",
    "        print(\"‚úÖ Feature engineering complete!\")\n",
    "        return pd.DataFrame(features)\n",
    "\n",
    "# Initialize feature engine\n",
    "feature_engine = FootballFeatureEngine(k_factor=30, form_window=10)\n",
    "print(\"‚úÖ Football Feature Engine initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bb7c9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting feature engineering on modern football data...\n",
      "üèóÔ∏è Building advanced features...\n",
      "   Processing match 0/31,253\n",
      "   Processing match 5,000/31,253\n",
      "   Processing match 10,000/31,253\n",
      "   Processing match 15,000/31,253\n",
      "   Processing match 20,000/31,253\n",
      "   Processing match 25,000/31,253\n",
      "   Processing match 30,000/31,253\n",
      "‚úÖ Feature engineering complete!\n",
      "\n",
      "üìä Features built for 31,253 matches\n",
      "üî¢ Total features: 25\n",
      "üìÖ Date range: 1990-01-12 00:00:00 to 2025-07-06 00:00:00\n",
      "\n",
      "üéØ Feature Summary:\n",
      "Numerical features: ['neutral', 'home_elo', 'away_elo', 'elo_diff', 'home_form_points', 'away_form_points', 'home_goals_for_avg', 'away_goals_for_avg', 'home_goals_against_avg', 'away_goals_against_avg', 'form_diff', 'h2h_home_wins', 'h2h_draws', 'h2h_away_wins', 'h2h_total_matches', 'home_tournament_exp', 'away_tournament_exp', 'tournament_exp_diff']\n",
      "\n",
      "üìã Sample features:\n",
      "  home_team  away_team     home_elo     away_elo   elo_diff  form_diff  result\n",
      "0   Algeria       Mali  1500.000000  1500.000000   0.000000        0.0       1\n",
      "1   Algeria   Cameroon  1537.500000  1500.000000  37.500000        3.0       1\n",
      "2    Greece    Belgium  1500.000000  1500.000000   0.000000        0.0       1\n",
      "3    Mexico  Argentina  1500.000000  1500.000000   0.000000        0.0       1\n",
      "4    Malawi   Tanzania  1500.000000  1500.000000   0.000000        0.0       0\n",
      "5  Eswatini   Botswana  1500.000000  1500.000000   0.000000        0.0       1\n",
      "6  Botswana     Malawi  1489.201950  1500.000000 -10.798050       -1.0       0\n",
      "7    Kuwait     France  1500.000000  1500.000000   0.000000        0.0      -1\n",
      "8  Eswatini   Tanzania  1510.798050  1500.000000  10.798050        2.0      -1\n",
      "9  Botswana   Tanzania  1489.667989  1519.627712 -29.959723       -1.5       0\n"
     ]
    }
   ],
   "source": [
    "# Build features from modern results\n",
    "print(\"üöÄ Starting feature engineering on modern football data...\")\n",
    "features_df = feature_engine.build_features(modern_results)\n",
    "\n",
    "print(f\"\\nüìä Features built for {len(features_df):,} matches\")\n",
    "print(f\"üî¢ Total features: {len(features_df.columns)}\")\n",
    "print(f\"üìÖ Date range: {features_df['date'].min()} to {features_df['date'].max()}\")\n",
    "\n",
    "# Display feature summary\n",
    "print(\"\\nüéØ Feature Summary:\")\n",
    "feature_cols = [col for col in features_df.columns if col not in ['home_team', 'away_team', 'date', 'tournament', 'home_score', 'away_score', 'result']]\n",
    "print(f\"Numerical features: {feature_cols}\")\n",
    "\n",
    "# Show sample of features\n",
    "print(\"\\nüìã Sample features:\")\n",
    "print(features_df[['home_team', 'away_team', 'home_elo', 'away_elo', 'elo_diff', 'form_diff', 'result']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527140cd",
   "metadata": {},
   "source": [
    "## 3. Machine Learning Models\n",
    "Building and optimizing multiple models for match outcome prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e219fa38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ World Cup Predictor initialized!\n"
     ]
    }
   ],
   "source": [
    "class WorldCupPredictor:\n",
    "    \"\"\"\n",
    "    Comprehensive World Cup prediction system using ensemble ML models.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.feature_importance = {}\n",
    "        self.scalers = {}\n",
    "        self.label_encoders = {}\n",
    "        self.best_model = None\n",
    "        \n",
    "    def prepare_data(self, features_df, test_size=0.2, min_date='2000-01-01'):\n",
    "        \"\"\"Prepare data for model training\"\"\"\n",
    "        print(\"üîß Preparing data for model training...\")\n",
    "        \n",
    "        # Filter recent data for better model performance\n",
    "        recent_data = features_df[features_df['date'] >= min_date].copy()\n",
    "        \n",
    "        # Define feature columns\n",
    "        feature_cols = [\n",
    "            'home_elo', 'away_elo', 'elo_diff',\n",
    "            'home_form_points', 'away_form_points', 'form_diff',\n",
    "            'home_goals_for_avg', 'away_goals_for_avg',\n",
    "            'home_goals_against_avg', 'away_goals_against_avg',\n",
    "            'h2h_home_wins', 'h2h_draws', 'h2h_away_wins', 'h2h_total_matches',\n",
    "            'home_tournament_exp', 'away_tournament_exp', 'tournament_exp_diff',\n",
    "            'neutral'\n",
    "        ]\n",
    "        \n",
    "        # Prepare features and target\n",
    "        X = recent_data[feature_cols].fillna(0)\n",
    "        # Keep simple numeric encoding: 1=home_win, 0=draw, -1=away_win -> 2=home_win, 1=draw, 0=away_win\n",
    "        y = recent_data['result'].map({1: 2, 0: 1, -1: 0})  # XGBoost likes 0-based classes\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns, index=X.index)\n",
    "        self.scalers['main'] = scaler\n",
    "        \n",
    "        # Split data chronologically (more realistic for time series)\n",
    "        split_date = recent_data['date'].quantile(0.8)\n",
    "        train_mask = recent_data['date'] <= split_date\n",
    "        \n",
    "        X_train = X_scaled[train_mask]\n",
    "        X_test = X_scaled[~train_mask]\n",
    "        y_train = y[train_mask]\n",
    "        y_test = y[~train_mask]\n",
    "        \n",
    "        print(f\"üìä Training data: {len(X_train):,} matches\")\n",
    "        print(f\"üß™ Test data: {len(X_test):,} matches\")\n",
    "        print(f\"üìÖ Split date: {split_date}\")\n",
    "        \n",
    "        # Handle class imbalance with SMOTE\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "        \n",
    "        print(f\"‚öñÔ∏è Balanced training data: {len(X_train_balanced):,} matches\")\n",
    "        \n",
    "        return X_train_balanced, X_test, y_train_balanced, y_test, feature_cols\n",
    "    \n",
    "    def create_models(self):\n",
    "        \"\"\"Create ensemble of ML models\"\"\"\n",
    "        models = {}\n",
    "        \n",
    "        # Random Forest\n",
    "        models['random_forest'] = RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=15,\n",
    "            min_samples_split=5,\n",
    "            min_samples_leaf=2,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        # Gradient Boosting (sklearn fallback if XGB fails)\n",
    "        models['gradient_boosting'] = GradientBoostingClassifier(\n",
    "            n_estimators=200,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=6,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # XGBoost (if available)\n",
    "        if XGB_AVAILABLE:\n",
    "            models['xgboost'] = xgb.XGBClassifier(\n",
    "                n_estimators=200,\n",
    "                learning_rate=0.1,\n",
    "                max_depth=6,\n",
    "                random_state=42,\n",
    "                eval_metric='mlogloss'\n",
    "            )\n",
    "        \n",
    "        # LightGBM (if available)\n",
    "        if LGB_AVAILABLE:\n",
    "            models['lightgbm'] = lgb.LGBMClassifier(\n",
    "                n_estimators=200,\n",
    "                learning_rate=0.1,\n",
    "                max_depth=6,\n",
    "                random_state=42,\n",
    "                verbose=-1\n",
    "            )\n",
    "        \n",
    "        # CatBoost (if available)\n",
    "        if CB_AVAILABLE:\n",
    "            models['catboost'] = cb.CatBoostClassifier(\n",
    "                iterations=200,\n",
    "                learning_rate=0.1,\n",
    "                depth=6,\n",
    "                random_state=42,\n",
    "                verbose=False\n",
    "            )\n",
    "        \n",
    "        return models\n",
    "    \n",
    "    def train_models(self, X_train, y_train, X_test, y_test):\n",
    "        \"\"\"Train all models and evaluate performance\"\"\"\n",
    "        print(\"üèãÔ∏è Training models...\")\n",
    "        \n",
    "        models = self.create_models()\n",
    "        results = {}\n",
    "        \n",
    "        for name, model in models.items():\n",
    "            print(f\"   Training {name}...\")\n",
    "            \n",
    "            # Train model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_prob = model.predict_proba(X_test)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            # Store results\n",
    "            results[name] = {\n",
    "                'model': model,\n",
    "                'accuracy': accuracy,\n",
    "                'predictions': y_pred,\n",
    "                'probabilities': y_prob\n",
    "            }\n",
    "            \n",
    "            print(f\"   ‚úÖ {name}: {accuracy:.4f} accuracy\")\n",
    "            \n",
    "            # Store feature importance if available\n",
    "            if hasattr(model, 'feature_importances_'):\n",
    "                self.feature_importance[name] = model.feature_importances_\n",
    "        \n",
    "        self.models = {name: result['model'] for name, result in results.items()}\n",
    "        \n",
    "        # Find best model\n",
    "        best_model_name = max(results.keys(), key=lambda x: results[x]['accuracy'])\n",
    "        self.best_model = self.models[best_model_name]\n",
    "        \n",
    "        print(f\"üèÜ Best model: {best_model_name} ({results[best_model_name]['accuracy']:.4f} accuracy)\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def create_ensemble(self, models_dict):\n",
    "        \"\"\"Create voting ensemble of best models\"\"\"\n",
    "        estimators = [(name, model) for name, model in models_dict.items()]\n",
    "        \n",
    "        ensemble = VotingClassifier(\n",
    "            estimators=estimators,\n",
    "            voting='soft'  # Use probability voting\n",
    "        )\n",
    "        \n",
    "        return ensemble\n",
    "    \n",
    "    def predict_match(self, home_team, away_team, features_dict):\n",
    "        \"\"\"Predict outcome of a single match\"\"\"\n",
    "        if self.best_model is None:\n",
    "            raise ValueError(\"Model not trained yet!\")\n",
    "        \n",
    "        # Prepare feature vector\n",
    "        feature_vector = np.array([[\n",
    "            features_dict['home_elo'],\n",
    "            features_dict['away_elo'],\n",
    "            features_dict['elo_diff'],\n",
    "            features_dict['home_form_points'],\n",
    "            features_dict['away_form_points'],\n",
    "            features_dict['form_diff'],\n",
    "            features_dict['home_goals_for_avg'],\n",
    "            features_dict['away_goals_for_avg'],\n",
    "            features_dict['home_goals_against_avg'],\n",
    "            features_dict['away_goals_against_avg'],\n",
    "            features_dict['h2h_home_wins'],\n",
    "            features_dict['h2h_draws'],\n",
    "            features_dict['h2h_away_wins'],\n",
    "            features_dict['h2h_total_matches'],\n",
    "            features_dict['home_tournament_exp'],\n",
    "            features_dict['away_tournament_exp'],\n",
    "            features_dict['tournament_exp_diff'],\n",
    "            features_dict['neutral']\n",
    "        ]])\n",
    "        \n",
    "        # Scale features\n",
    "        feature_vector_scaled = self.scalers['main'].transform(feature_vector)\n",
    "        \n",
    "        # Get prediction probabilities\n",
    "        probabilities = self.best_model.predict_proba(feature_vector_scaled)[0]\n",
    "        prediction_encoded = self.best_model.predict(feature_vector_scaled)[0]\n",
    "        \n",
    "        # Map back to meaningful labels\n",
    "        class_mapping = {0: 'away_win', 1: 'draw', 2: 'home_win'}\n",
    "        prediction = class_mapping[prediction_encoded]\n",
    "        \n",
    "        # Map probabilities to outcomes\n",
    "        prob_dict = {\n",
    "            'away_win': probabilities[0],\n",
    "            'draw': probabilities[1],\n",
    "            'home_win': probabilities[2]\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'prediction': prediction,\n",
    "            'probabilities': prob_dict,\n",
    "            'home_win_prob': prob_dict.get('home_win', 0),\n",
    "            'draw_prob': prob_dict.get('draw', 0),\n",
    "            'away_win_prob': prob_dict.get('away_win', 0)\n",
    "        }\n",
    "\n",
    "# Initialize predictor\n",
    "predictor = WorldCupPredictor()\n",
    "print(\"‚úÖ World Cup Predictor initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32db1585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Training World Cup prediction models...\n",
      "üîß Preparing data for model training...\n",
      "üìä Training data: 19,462 matches\n",
      "üß™ Test data: 4,848 matches\n",
      "üìÖ Split date: 2020-10-14 00:00:00\n",
      "‚öñÔ∏è Balanced training data: 28,101 matches\n",
      "üèãÔ∏è Training models...\n",
      "   Training random_forest...\n",
      "   ‚úÖ random_forest: 0.5918 accuracy\n",
      "   Training gradient_boosting...\n",
      "   ‚úÖ gradient_boosting: 0.5901 accuracy\n",
      "   Training xgboost...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1 2], got ['away_win' 'draw' 'home_win']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m X_train, X_test, y_train, y_test, feature_cols = predictor.prepare_data(features_df)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Train models\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m results = \u001b[43mpredictor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Display results\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müìä Model Performance Summary:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 126\u001b[39m, in \u001b[36mWorldCupPredictor.train_models\u001b[39m\u001b[34m(self, X_train, y_train, X_test, y_test)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Training \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[32m    129\u001b[39m y_pred = model.predict(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Big Things/ML/world-cup/.venv/lib/python3.13/site-packages/xgboost/core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Big Things/ML/world-cup/.venv/lib/python3.13/site-packages/xgboost/sklearn.py:1640\u001b[39m, in \u001b[36mXGBClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1635\u001b[39m     expected_classes = \u001b[38;5;28mself\u001b[39m.classes_\n\u001b[32m   1636\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1637\u001b[39m     classes.shape != expected_classes.shape\n\u001b[32m   1638\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (classes == expected_classes).all()\n\u001b[32m   1639\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1640\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1641\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1642\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1643\u001b[39m     )\n\u001b[32m   1645\u001b[39m params = \u001b[38;5;28mself\u001b[39m.get_xgb_params()\n\u001b[32m   1647\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.objective):\n",
      "\u001b[31mValueError\u001b[39m: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2], got ['away_win' 'draw' 'home_win']"
     ]
    }
   ],
   "source": [
    "# Train the models\n",
    "print(\"üöÄ Training World Cup prediction models...\")\n",
    "\n",
    "# Prepare data\n",
    "X_train, X_test, y_train, y_test, feature_cols = predictor.prepare_data(features_df)\n",
    "\n",
    "# Train models\n",
    "results = predictor.train_models(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nüìä Model Performance Summary:\")\n",
    "print(\"-\" * 50)\n",
    "for name, result in results.items():\n",
    "    print(f\"{name:15}: {result['accuracy']:.4f} accuracy\")\n",
    "\n",
    "# Show classification report for best model\n",
    "best_model_name = max(results.keys(), key=lambda x: results[x]['accuracy'])\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
    "print(\"\\nüìà Classification Report:\")\n",
    "print(classification_report(y_test, results[best_model_name]['predictions']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28609ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Training World Cup prediction models (v2)...\n",
      "üîß Preparing data for model training...\n",
      "üìä Training data: 19,462 matches\n",
      "üß™ Test data: 4,848 matches\n",
      "üìÖ Split date: 2020-10-14 00:00:00\n",
      "‚öñÔ∏è Balanced training data: 28,101 matches\n",
      "‚ö†Ô∏è Skipping XGBoost due to compatibility issues\n",
      "üèãÔ∏è Training models...\n",
      "   Training random_forest...\n",
      "   ‚úÖ random_forest: 0.5918 accuracy\n",
      "   Training gradient_boosting...\n",
      "   ‚úÖ gradient_boosting: 0.5901 accuracy\n",
      "   Training lightgbm...\n",
      "   ‚úÖ lightgbm: 0.5928 accuracy\n",
      "   Training catboost...\n",
      "   ‚úÖ catboost: 0.5998 accuracy\n",
      "\n",
      "üèÜ Best model: catboost (0.5998 accuracy)\n",
      "\n",
      "üìä Model Performance Summary:\n",
      "--------------------------------------------------\n",
      "random_forest  : 0.5918 accuracy\n",
      "gradient_boosting: 0.5901 accuracy\n",
      "lightgbm       : 0.5928 accuracy\n",
      "catboost       : 0.5998 accuracy\n",
      "\n",
      "üìà Classification Report for catboost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    away_win       0.57      0.63      0.60      1393\n",
      "        draw       0.31      0.15      0.20      1112\n",
      "    home_win       0.67      0.80      0.73      2343\n",
      "\n",
      "    accuracy                           0.60      4848\n",
      "   macro avg       0.52      0.52      0.51      4848\n",
      "weighted avg       0.56      0.60      0.57      4848\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a new predictor instance to avoid XGBoost state issues\n",
    "predictor = WorldCupPredictor()\n",
    "\n",
    "print(\"üöÄ Training World Cup prediction models (v2)...\")\n",
    "\n",
    "# Prepare data\n",
    "X_train, X_test, y_train, y_test, feature_cols = predictor.prepare_data(features_df)\n",
    "\n",
    "# Train models (skip XGBoost if it continues to have issues)\n",
    "models = predictor.create_models()\n",
    "if 'xgboost' in models:\n",
    "    del models['xgboost']  # Remove XGBoost for now\n",
    "    print(\"‚ö†Ô∏è Skipping XGBoost due to compatibility issues\")\n",
    "\n",
    "# Train remaining models manually\n",
    "results = {}\n",
    "print(\"üèãÔ∏è Training models...\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"   Training {name}...\")\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'predictions': y_pred,\n",
    "        'probabilities': y_prob\n",
    "    }\n",
    "    \n",
    "    print(f\"   ‚úÖ {name}: {accuracy:.4f} accuracy\")\n",
    "\n",
    "# Store models and find best one\n",
    "predictor.models = {name: result['model'] for name, result in results.items()}\n",
    "best_model_name = max(results.keys(), key=lambda x: results[x]['accuracy'])\n",
    "predictor.best_model = predictor.models[best_model_name]\n",
    "\n",
    "print(f\"\\nüèÜ Best model: {best_model_name} ({results[best_model_name]['accuracy']:.4f} accuracy)\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nüìä Model Performance Summary:\")\n",
    "print(\"-\" * 50)\n",
    "for name, result in results.items():\n",
    "    print(f\"{name:15}: {result['accuracy']:.4f} accuracy\")\n",
    "\n",
    "# Show classification report for best model\n",
    "print(f\"\\nüìà Classification Report for {best_model_name}:\")\n",
    "# y_test and predictions should already be numeric (0, 1, 2)\n",
    "label_names = ['away_win', 'draw', 'home_win']\n",
    "print(classification_report(y_test, results[best_model_name]['predictions'], target_names=label_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c42560d",
   "metadata": {},
   "source": [
    "## 4. World Cup Tournament Simulation\n",
    "Creating a complete World Cup simulation engine with group stages and knockout rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0486a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ World Cup Simulator initialized!\n"
     ]
    }
   ],
   "source": [
    "class WorldCupSimulator:\n",
    "    \"\"\"\n",
    "    Complete World Cup tournament simulation engine.\n",
    "    \n",
    "    Features:\n",
    "    - Group stage simulation\n",
    "    - Knockout round simulation\n",
    "    - Real-time ELO rating updates\n",
    "    - Penalty shootout simulation\n",
    "    - Tournament bracket management\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, predictor, feature_engine):\n",
    "        self.predictor = predictor\n",
    "        self.feature_engine = feature_engine\n",
    "        self.current_elos = {}\n",
    "        self.tournament_results = {}\n",
    "        self.group_tables = {}\n",
    "        self.knockout_bracket = {}\n",
    "        \n",
    "    def get_team_current_features(self, team, opponent, tournament='FIFA World Cup', neutral=True):\n",
    "        \"\"\"Get current features for a team based on historical data\"\"\"\n",
    "        current_date = datetime.now()\n",
    "        \n",
    "        # Get current ELO (use final ELO from feature engine)\n",
    "        team_elo = self.feature_engine.elo_ratings.get(team, 1500)\n",
    "        opponent_elo = self.feature_engine.elo_ratings.get(opponent, 1500)\n",
    "        \n",
    "        # Calculate recent form (last 10 matches)\n",
    "        team_form = self.feature_engine.calculate_team_form(team, current_date, modern_results, 10)\n",
    "        opponent_form = self.feature_engine.calculate_team_form(opponent, current_date, modern_results, 10)\n",
    "        \n",
    "        # Head-to-head record\n",
    "        h2h = self.feature_engine.head_to_head_record(team, opponent, current_date, modern_results)\n",
    "        \n",
    "        # Tournament experience\n",
    "        team_wc_exp = self.feature_engine.tournament_experience(team, 'FIFA World Cup', current_date, modern_results)\n",
    "        opponent_wc_exp = self.feature_engine.tournament_experience(opponent, 'FIFA World Cup', current_date, modern_results)\n",
    "        \n",
    "        return {\n",
    "            'home_elo': team_elo,\n",
    "            'away_elo': opponent_elo,\n",
    "            'elo_diff': team_elo - opponent_elo,\n",
    "            'home_form_points': team_form['form_points'],\n",
    "            'away_form_points': opponent_form['form_points'],\n",
    "            'form_diff': team_form['form_points'] - opponent_form['form_points'],\n",
    "            'home_goals_for_avg': team_form['goals_for'],\n",
    "            'away_goals_for_avg': opponent_form['goals_for'],\n",
    "            'home_goals_against_avg': team_form['goals_against'],\n",
    "            'away_goals_against_avg': opponent_form['goals_against'],\n",
    "            'h2h_home_wins': h2h['h2h_wins'],\n",
    "            'h2h_draws': h2h['h2h_draws'],\n",
    "            'h2h_away_wins': h2h['h2h_losses'],\n",
    "            'h2h_total_matches': h2h['h2h_matches'],\n",
    "            'home_tournament_exp': team_wc_exp,\n",
    "            'away_tournament_exp': opponent_wc_exp,\n",
    "            'tournament_exp_diff': team_wc_exp - opponent_wc_exp,\n",
    "            'neutral': 1 if neutral else 0\n",
    "        }\n",
    "    \n",
    "    def simulate_match(self, team1, team2, is_neutral=True, is_knockout=False):\n",
    "        \"\"\"Simulate a single match between two teams\"\"\"\n",
    "        features = self.get_team_current_features(team1, team2, neutral=is_neutral)\n",
    "        \n",
    "        # Get prediction\n",
    "        prediction_result = self.predictor.predict_match(team1, team2, features)\n",
    "        \n",
    "        # Simulate actual score based on probabilities\n",
    "        outcome_prob = np.random.random()\n",
    "        \n",
    "        if outcome_prob < prediction_result['home_win_prob']:\n",
    "            # Home team wins\n",
    "            home_score = np.random.choice([1, 2, 3, 4], p=[0.4, 0.35, 0.2, 0.05])\n",
    "            away_score = np.random.choice([0, 1], p=[0.7, 0.3]) if home_score > 1 else 0\n",
    "            result = 'home_win'\n",
    "        elif outcome_prob < prediction_result['home_win_prob'] + prediction_result['draw_prob']:\n",
    "            # Draw\n",
    "            score = np.random.choice([0, 1, 2], p=[0.3, 0.5, 0.2])\n",
    "            home_score = away_score = score\n",
    "            result = 'draw'\n",
    "        else:\n",
    "            # Away team wins\n",
    "            away_score = np.random.choice([1, 2, 3, 4], p=[0.4, 0.35, 0.2, 0.05])\n",
    "            home_score = np.random.choice([0, 1], p=[0.7, 0.3]) if away_score > 1 else 0\n",
    "            result = 'away_win'\n",
    "        \n",
    "        # Handle knockout stage draws\n",
    "        if is_knockout and result == 'draw':\n",
    "            # Extra time/penalties\n",
    "            penalty_winner = np.random.choice([team1, team2])\n",
    "            result = 'home_win' if penalty_winner == team1 else 'away_win'\n",
    "            \n",
    "        return {\n",
    "            'home_team': team1,\n",
    "            'away_team': team2,\n",
    "            'home_score': home_score,\n",
    "            'away_score': away_score,\n",
    "            'result': result,\n",
    "            'probabilities': prediction_result['probabilities'],\n",
    "            'penalty_shootout': is_knockout and home_score == away_score\n",
    "        }\n",
    "    \n",
    "    def simulate_group_stage(self, groups):\n",
    "        \"\"\"Simulate the group stage of the World Cup\"\"\"\n",
    "        print(\"‚öΩ Simulating Group Stage...\")\n",
    "        \n",
    "        group_tables = {}\n",
    "        all_matches = []\n",
    "        \n",
    "        for group_name, teams in groups.items():\n",
    "            print(f\"   Group {group_name}: {', '.join(teams)}\")\n",
    "            \n",
    "            # Initialize group table\n",
    "            table = {team: {'points': 0, 'goals_for': 0, 'goals_against': 0, 'goal_diff': 0, 'played': 0} \n",
    "                    for team in teams}\n",
    "            \n",
    "            # Generate all group matches (round-robin)\n",
    "            group_matches = []\n",
    "            for i, team1 in enumerate(teams):\n",
    "                for j, team2 in enumerate(teams[i+1:], i+1):\n",
    "                    match = self.simulate_match(team1, team2, is_neutral=True)\n",
    "                    group_matches.append(match)\n",
    "                    all_matches.append(match)\n",
    "                    \n",
    "                    # Update table\n",
    "                    home_team, away_team = match['home_team'], match['away_team']\n",
    "                    home_score, away_score = match['home_score'], match['away_score']\n",
    "                    \n",
    "                    # Update stats\n",
    "                    table[home_team]['goals_for'] += home_score\n",
    "                    table[home_team]['goals_against'] += away_score\n",
    "                    table[home_team]['goal_diff'] = table[home_team]['goals_for'] - table[home_team]['goals_against']\n",
    "                    table[home_team]['played'] += 1\n",
    "                    \n",
    "                    table[away_team]['goals_for'] += away_score\n",
    "                    table[away_team]['goals_against'] += home_score\n",
    "                    table[away_team]['goal_diff'] = table[away_team]['goals_for'] - table[away_team]['goals_against']\n",
    "                    table[away_team]['played'] += 1\n",
    "                    \n",
    "                    # Award points\n",
    "                    if match['result'] == 'home_win':\n",
    "                        table[home_team]['points'] += 3\n",
    "                    elif match['result'] == 'away_win':\n",
    "                        table[away_team]['points'] += 3\n",
    "                    else:  # draw\n",
    "                        table[home_team]['points'] += 1\n",
    "                        table[away_team]['points'] += 1\n",
    "            \n",
    "            # Sort table by points, then goal difference, then goals for\n",
    "            sorted_teams = sorted(table.items(), \n",
    "                                key=lambda x: (x[1]['points'], x[1]['goal_diff'], x[1]['goals_for']), \n",
    "                                reverse=True)\n",
    "            \n",
    "            group_tables[group_name] = {\n",
    "                'table': sorted_teams,\n",
    "                'qualified': [sorted_teams[0][0], sorted_teams[1][0]],  # Top 2 teams\n",
    "                'matches': group_matches\n",
    "            }\n",
    "            \n",
    "            print(f\"      Qualified: {group_tables[group_name]['qualified'][0]} & {group_tables[group_name]['qualified'][1]}\")\n",
    "        \n",
    "        self.group_tables = group_tables\n",
    "        return group_tables, all_matches\n",
    "    \n",
    "    def simulate_knockout_round(self, teams, round_name):\n",
    "        \"\"\"Simulate a knockout round\"\"\"\n",
    "        print(f\"üèÜ Simulating {round_name}...\")\n",
    "        \n",
    "        if len(teams) % 2 != 0:\n",
    "            raise ValueError(\"Number of teams must be even for knockout rounds\")\n",
    "        \n",
    "        winners = []\n",
    "        matches = []\n",
    "        \n",
    "        for i in range(0, len(teams), 2):\n",
    "            team1, team2 = teams[i], teams[i+1]\n",
    "            match = self.simulate_match(team1, team2, is_neutral=True, is_knockout=True)\n",
    "            matches.append(match)\n",
    "            \n",
    "            # Determine winner\n",
    "            if match['result'] == 'home_win':\n",
    "                winner = team1\n",
    "            else:\n",
    "                winner = team2\n",
    "                \n",
    "            winners.append(winner)\n",
    "            \n",
    "            penalty_info = \" (Penalties)\" if match.get('penalty_shootout', False) else \"\"\n",
    "            print(f\"   {team1} vs {team2}: {winner} wins{penalty_info}\")\n",
    "        \n",
    "        return winners, matches\n",
    "    \n",
    "    def simulate_full_tournament(self, qualified_teams):\n",
    "        \"\"\"Simulate a complete World Cup tournament\"\"\"\n",
    "        print(\"üåç STARTING WORLD CUP SIMULATION\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Organize teams into groups (8 groups of 4 teams)\n",
    "        if len(qualified_teams) != 32:\n",
    "            raise ValueError(\"World Cup requires exactly 32 teams\")\n",
    "        \n",
    "        # Create balanced groups (simplified random grouping)\n",
    "        np.random.shuffle(qualified_teams)\n",
    "        groups = {}\n",
    "        group_letters = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n",
    "        \n",
    "        for i, letter in enumerate(group_letters):\n",
    "            groups[letter] = qualified_teams[i*4:(i+1)*4]\n",
    "        \n",
    "        # Simulate group stage\n",
    "        group_results, group_matches = self.simulate_group_stage(groups)\n",
    "        \n",
    "        # Get qualified teams for Round of 16\n",
    "        round_of_16_teams = []\n",
    "        for group_name in group_letters:\n",
    "            round_of_16_teams.extend(group_results[group_name]['qualified'])\n",
    "        \n",
    "        print(f\"\\nüèÜ Round of 16 Teams: {', '.join(round_of_16_teams)}\")\n",
    "        \n",
    "        # Simulate knockout stages\n",
    "        tournament_results = {\n",
    "            'group_stage': group_results,\n",
    "            'group_matches': group_matches\n",
    "        }\n",
    "        \n",
    "        # Round of 16\n",
    "        quarterfinal_teams, round16_matches = self.simulate_knockout_round(round_of_16_teams, \"Round of 16\")\n",
    "        tournament_results['round_of_16'] = round16_matches\n",
    "        \n",
    "        # Quarter-finals\n",
    "        semifinal_teams, quarterfinal_matches = self.simulate_knockout_round(quarterfinal_teams, \"Quarter-finals\")\n",
    "        tournament_results['quarter_finals'] = quarterfinal_matches\n",
    "        \n",
    "        # Semi-finals\n",
    "        final_teams, semifinal_matches = self.simulate_knockout_round(semifinal_teams, \"Semi-finals\")\n",
    "        tournament_results['semi_finals'] = semifinal_matches\n",
    "        \n",
    "        # Third place play-off (losers of semi-finals)\n",
    "        losing_semifinalists = [team for team in semifinal_teams if team not in final_teams]\n",
    "        if len(losing_semifinalists) == 2:\n",
    "            third_place_match = self.simulate_match(losing_semifinalists[0], losing_semifinalists[1], \n",
    "                                                  is_neutral=True, is_knockout=True)\n",
    "            third_place_winner = losing_semifinalists[0] if third_place_match['result'] == 'home_win' else losing_semifinalists[1]\n",
    "            tournament_results['third_place'] = third_place_match\n",
    "            print(f\"ü•â Third Place: {third_place_winner}\")\n",
    "        \n",
    "        # Final\n",
    "        final_match = self.simulate_match(final_teams[0], final_teams[1], is_neutral=True, is_knockout=True)\n",
    "        champion = final_teams[0] if final_match['result'] == 'home_win' else final_teams[1]\n",
    "        runner_up = final_teams[1] if champion == final_teams[0] else final_teams[0]\n",
    "        \n",
    "        tournament_results['final'] = final_match\n",
    "        tournament_results['champion'] = champion\n",
    "        tournament_results['runner_up'] = runner_up\n",
    "        \n",
    "        print(f\"\\nüèÜ WORLD CUP CHAMPION: {champion}\")\n",
    "        print(f\"ü•à Runner-up: {runner_up}\")\n",
    "        \n",
    "        penalty_info = \" (Penalties)\" if final_match.get('penalty_shootout', False) else \"\"\n",
    "        print(f\"üéØ Final Score: {final_teams[0]} {final_match['home_score']}-{final_match['away_score']} {final_teams[1]}{penalty_info}\")\n",
    "        \n",
    "        self.tournament_results = tournament_results\n",
    "        return tournament_results\n",
    "\n",
    "# Initialize simulator\n",
    "simulator = WorldCupSimulator(predictor, feature_engine)\n",
    "print(\"‚úÖ World Cup Simulator initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60179e42",
   "metadata": {},
   "source": [
    "## 5. API Backend for Dashboard\n",
    "Creating FastAPI endpoints for the React dashboard integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95cc78d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Models saved!\n",
      "üìä Available teams: 322\n",
      "üî§ Sample teams: ['Abkhazia', 'Afghanistan', 'Albania', 'Alderney', 'Algeria', 'Ambazonia', 'American Samoa', 'Andalusia', 'Andorra', 'Angola']\n",
      "\n",
      "üöÄ Creating FastAPI backend...\n"
     ]
    }
   ],
   "source": [
    "# Save the trained models and components for the API\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Create models directory\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save just the essential components\n",
    "joblib.dump(predictor.best_model, 'models/best_model.pkl')\n",
    "joblib.dump(predictor.scalers, 'models/scalers.pkl')\n",
    "joblib.dump(feature_engine.elo_ratings, 'models/elo_ratings.pkl')\n",
    "\n",
    "# Save the features dataframe for quick access\n",
    "features_df.to_pickle('models/features_df.pkl')\n",
    "\n",
    "# Get available teams from the dataset\n",
    "available_teams = sorted(list(set(modern_results['home_team'].unique()) | set(modern_results['away_team'].unique())))\n",
    "\n",
    "joblib.dump(available_teams, 'models/available_teams.pkl')\n",
    "\n",
    "print(f\"‚úÖ Models saved!\")\n",
    "print(f\"üìä Available teams: {len(available_teams)}\")\n",
    "print(f\"üî§ Sample teams: {available_teams[:10]}\")\n",
    "\n",
    "# Create the FastAPI application\n",
    "print(\"\\nüöÄ Creating FastAPI backend...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8214f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Testing World Cup Simulator...\n",
      "Available realistic teams: 32/32\n",
      "\\nSimulating World Cup with teams: Brazil, Argentina, France, Germany, Spain, England, Portugal, Netherlands...\n",
      "üåç STARTING WORLD CUP SIMULATION\n",
      "==================================================\n",
      "‚öΩ Simulating Group Stage...\n",
      "   Group A: Italy, Senegal, Switzerland, Belgium\n",
      "      Qualified: Italy & Senegal\n",
      "   Group B: Morocco, Colombia, Serbia, Saudi Arabia\n",
      "      Qualified: Colombia & Morocco\n",
      "   Group C: Germany, Portugal, Canada, Ecuador\n",
      "      Qualified: Canada & Ecuador\n",
      "   Group D: Argentina, Japan, England, Tunisia\n",
      "      Qualified: England & Argentina\n",
      "   Group E: Costa Rica, Denmark, Mexico, United States\n",
      "      Qualified: Denmark & United States\n",
      "   Group F: Uruguay, France, Croatia, Wales\n",
      "      Qualified: Croatia & Uruguay\n",
      "   Group G: Poland, Brazil, Netherlands, Australia\n",
      "      Qualified: Brazil & Netherlands\n",
      "   Group H: Ghana, South Korea, Spain, Iran\n",
      "      Qualified: Spain & Ghana\n",
      "\n",
      "üèÜ Round of 16 Teams: Italy, Senegal, Colombia, Morocco, Canada, Ecuador, England, Argentina, Denmark, United States, Croatia, Uruguay, Brazil, Netherlands, Spain, Ghana\n",
      "üèÜ Simulating Round of 16...\n",
      "   Italy vs Senegal: Italy wins\n",
      "   Colombia vs Morocco: Colombia wins\n",
      "   Canada vs Ecuador: Canada wins\n",
      "   England vs Argentina: Argentina wins\n",
      "   Denmark vs United States: United States wins (Penalties)\n",
      "   Croatia vs Uruguay: Croatia wins\n",
      "   Brazil vs Netherlands: Netherlands wins (Penalties)\n",
      "   Spain vs Ghana: Spain wins\n",
      "üèÜ Simulating Quarter-finals...\n",
      "   Italy vs Colombia: Colombia wins\n",
      "   Canada vs Argentina: Argentina wins\n",
      "   United States vs Croatia: Croatia wins (Penalties)\n",
      "   Netherlands vs Spain: Netherlands wins\n",
      "üèÜ Simulating Semi-finals...\n",
      "   Colombia vs Argentina: Colombia wins\n",
      "   Croatia vs Netherlands: Netherlands wins\n",
      "ü•â Third Place: Argentina\n",
      "\n",
      "üèÜ WORLD CUP CHAMPION: Colombia\n",
      "ü•à Runner-up: Netherlands\n",
      "üéØ Final Score: Colombia 1-0 Netherlands\n",
      "\\nüéâ Tournament simulation completed successfully!\n",
      "üèÜ Champion: Colombia\n",
      "ü•à Runner-up: Netherlands\n",
      "\\nüìä Sample Group Results:\n",
      "  Group A: Italy, Senegal qualified\n",
      "  Group B: Colombia, Morocco qualified\n",
      "\\n‚úÖ World Cup Predictor setup complete!\n",
      "============================================================\n",
      "üöÄ Ready for deployment!\n",
      "üìñ Check README.md for deployment instructions\n",
      "üåê Backend API: http://localhost:8000\n",
      "üíª Frontend Dashboard: http://localhost:3000\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test the simulator with a sample World Cup\n",
    "print(\"üéØ Testing World Cup Simulator...\")\n",
    "\n",
    "# Select 32 realistic teams for World Cup 2026\n",
    "realistic_teams = [\n",
    "    'Brazil', 'Argentina', 'France', 'Germany', 'Spain', 'England', \n",
    "    'Portugal', 'Netherlands', 'Italy', 'Belgium', 'Croatia', 'Mexico',\n",
    "    'Uruguay', 'Colombia', 'Japan', 'South Korea', 'Morocco', 'Denmark',\n",
    "    'Switzerland', 'Poland', 'Serbia', 'Canada', 'Australia', 'Ghana',\n",
    "    'Senegal', 'Ecuador', 'Tunisia', 'Costa Rica', 'Wales', 'Iran',\n",
    "    'Saudi Arabia', 'United States'\n",
    "]\n",
    "\n",
    "# Verify all teams are available\n",
    "available_realistic_teams = [team for team in realistic_teams if team in available_teams]\n",
    "print(f\"Available realistic teams: {len(available_realistic_teams)}/32\")\n",
    "\n",
    "if len(available_realistic_teams) >= 32:\n",
    "    # Run a sample tournament simulation\n",
    "    tournament_teams = available_realistic_teams[:32]\n",
    "    print(f\"\\\\nSimulating World Cup with teams: {', '.join(tournament_teams[:8])}...\")\n",
    "    \n",
    "    try:\n",
    "        result = simulator.simulate_full_tournament(tournament_teams)\n",
    "        \n",
    "        print(f\"\\\\nüéâ Tournament simulation completed successfully!\")\n",
    "        print(f\"üèÜ Champion: {result['champion']}\")\n",
    "        print(f\"ü•à Runner-up: {result['runner_up']}\")\n",
    "        \n",
    "        # Show some group results\n",
    "        print(f\"\\\\nüìä Sample Group Results:\")\n",
    "        for group_name, group_data in list(result['group_stage'].items())[:2]:\n",
    "            print(f\"  Group {group_name}: {', '.join(group_data['qualified'])} qualified\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Simulation failed: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Not enough realistic teams available for full simulation\")\n",
    "\n",
    "print(\"\\\\n‚úÖ World Cup Predictor setup complete!\")\n",
    "print(\"=\"*60)\n",
    "print(\"üöÄ Ready for deployment!\")\n",
    "print(\"üìñ Check README.md for deployment instructions\")\n",
    "print(\"üåê Backend API: http://localhost:8000\")\n",
    "print(\"üíª Frontend Dashboard: http://localhost:3000\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
